---
output:
  github_document:
    pandoc_args: --webtex=https://chart.googleapis.com/chart?cht=tx&chl=
bibliography: README.bib
---

## Fast Sum-Kernel Approximation

[![Build Status on Travis](https://travis-ci.org/boennecd/FSKA.svg?branch=master,osx)](https://travis-ci.org/boennecd/FSKA)

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  error = FALSE, cache = "./README-cache/", fig.path = "./README-fig/", 
  echo = TRUE)
options(digits = 4, scipen = 7)
```

This package contains a simple implementation of the dual-tree method like the one 
suggested by @Gray03 and shown in @Klaas06. The problem we want to solve is
the sum-kernel problem in @Klaas06. Particularly, we consider the situation 
where we have $1,\dots,N_q$ query particles denoted by 
$\{\vec Y_i\}_{i=1,\dots,N_q}$ and $1,\dots,N_s$ source particles denoted by
$\{\vec X_j\}_{j=1,\dots,N_s}$. For each query particle, we want to compute 
the weights 

$$W_i = \frac{\tilde W_i}{\sum_{k = 1}^{N_q} \tilde W_i},\qquad \tilde W_i = \sum_{j=1}^{N_s} \bar W_j K(\vec Y_i, \vec X_j)$$

where each source particle has an associated weight $\bar W_j$ and $K$ is a
kernel. Computing the above is $\mathcal{O}(N_sN_q)$ which is major 
bottleneck if $N_s$ and $N_q$ is large. However, one can use a 
[k-d tree](https://en.wikipedia.org/wiki/K-d_tree) for the query particles
and source particles and exploit that:

- $W_j K(\vec Y_i, \vec X_j)$ is almost zero for some pairs of nodes in the 
two k-d trees. 
- $K(\cdot, \vec X_j)$ is almost identical for some nodes in the k-d tree 
for the source particles. 

Thus, a substantial amount of computation can be skipped or approximated 
with e.g., the centroid in the source node with only a minor
loss of precision. The dual-tree approximation method is 
$\mathcal{O}(N_s\log N_s)$ and $\mathcal{O}(N_q\log N_q)$.
We start by defining a function to simulate the source 
and query particles (we will let the two sets be identical for simplicity). 
Further, we plot one draw of simulated points and illustrate the leafs in 
the k-d tree.

```{r sim_func}
######
# define function to simulate data
mus <- matrix(c(-1, -1, 
                 1, 1, 
                -1, 1), 3L, byrow = FALSE)
mus <- mus * .75
Sig <- diag(c(.5^2, .25^2))

get_sims <- function(n_per_grp){
  # simulate X
  sims <- lapply(1:nrow(mus), function(i){
    mu <- mus[i, ]
    X <- matrix(rnorm(n_per_grp * 2L), nrow = 2L)
    X <- t(crossprod(chol(Sig), X) + mu)
    
    data.frame(X, grp = i)
  })
  sims <- do.call(rbind, sims)
  X <- t(as.matrix(sims[, c("X1", "X2")]))
  
  # simulate weights
  ws <- exp(rnorm(ncol(X)))
  ws <- ws / sum(ws)
  
  list(sims = sims, X = X, ws = ws)
}

#####
# show example 
set.seed(42452654)
invisible(list2env(get_sims(5000L), environment()))

# plot points
par(mar = c(5, 4, .5, .5))
plot(as.matrix(sims[, c("X1", "X2")]), col = sims$grp + 1L)

# find KD-tree and add borders 
out <- FSKA:::test_KD_note(X, 50L)
out$indices <- out$indices + 1L
n_ele <- drop(out$n_elems)
idx <- mapply(`:`, cumsum(c(1L, head(n_ele, -1))), cumsum(n_ele))
stopifnot(all(sapply(idx, length) == n_ele))
idx <- lapply(idx, function(i) out$indices[i])
stopifnot(!anyDuplicated(unlist(idx)), length(unlist(idx)) == ncol(X))

grps <- lapply(idx, function(i) X[, i])

borders <- lapply(grps, function(x) apply(x, 1, range))
invisible(lapply(borders, function(b) 
  rect(b[1, "X1"], b[1, "X2"], b[2, "X1"], b[2, "X2"])))
```

Next, we compute the run-times for the previous examples and compare the 
approximations of the un-normalized log weights, $\log \tilde W_i$, and 
normalized weights, $W_i$. The `n_threads` sets the number of threads to 
use in the methods.

```{r comp_run_times, cache = 1}
# run-times
microbenchmark::microbenchmark(
  `dual tree 1` = FSKA:::FSKA (X = X, ws = ws, Y = X, N_min = 10L, 
                               eps = 5e-3, n_threads = 1L),
  `dual tree 6` = FSKA:::FSKA (X = X, ws = ws, Y = X, N_min = 10L, 
                               eps = 5e-3, n_threads = 4L),
  `naive 1`     = FSKA:::naive(X = X, ws = ws, Y = X, n_threads = 1L),
  `naive 6`     = FSKA:::naive(X = X, ws = ws, Y = X, n_threads = 4L),
  times = 10L)

# The functions return the un-normalized log weights. We first compare
# the result on this scale
o1 <- FSKA:::FSKA  (X = X, ws = ws, Y = X, N_min = 10L, eps = 5e-3, 
                    n_threads = 1L)
o2 <- FSKA:::naive(X = X, ws = ws, Y = X, n_threads = 4L)

all.equal(o1, o2)
par(mar = c(5, 4, .5, .5))
hist((o1 - o2)/ abs((o1 + o2) / 2), breaks = 50, main = "", 
     xlab = "Delta un-normalized log weights")

# then we compare the normalized weights
func <- function(x){
  x_max <- max(x)
  x <- exp(x - x_max)
  x / sum(x)
}

o1 <- func(o1)
o2 <- func(o2)
all.equal(o1, o2)
hist((o1 - o2)/ abs((o1 + o2) / 2), breaks = 50, main = "", 
     xlab = "Delta normalized log weights")
```

Finally, we compare the run-times as function of $N = N_s = N_q$. The dashed 
line is "naive" method, the continuous line is the dual-tree method, and the 
dotted line is dual-tree method using 1 thread.

```{r run_times_N, cache = 1}
Ns <- 2^(7:14)
run_times <- lapply(Ns, function(N){
  invisible(list2env(get_sims(N), environment()))
  microbenchmark::microbenchmark(
    `dual-tree`   = FSKA:::FSKA (X = X, ws = ws, Y = X, N_min = 10L, eps = 5e-3, 
                               n_threads = 4L),
    naive         = FSKA:::naive(X = X, ws = ws, Y = X, n_threads = 4L),
    `dual-tree 1` = FSKA:::FSKA (X = X, ws = ws, Y = X, N_min = 10L, eps = 5e-3, 
                               n_threads = 1L), 
    times = 5L)
})

Ns_xtra <- 2^(15:19)
run_times_xtra <- lapply(Ns_xtra, function(N){
  invisible(list2env(get_sims(N), environment()))
  microbenchmark::microbenchmark(
    `dual-tree` = FSKA:::FSKA (X = X, ws = ws, Y = X, N_min = 10L, eps = 5e-3, 
                               n_threads = 4L),
    times = 5L)
})
```

```{r plot_run_times_N}
library(microbenchmark)
meds <- t(sapply(run_times, function(x) summary(x, unit = "s")[, "median"]))
meds_xtra <- 
  sapply(run_times_xtra, function(x) summary(x, unit = "s")[, "median"])
meds <- rbind(meds, cbind(meds_xtra, NA_real_, NA_real_))
dimnames(meds) <- list(
  N = c(Ns, Ns_xtra) * 3L, method = c("Dual-tree", "Naive", "Dual-tree 1"))
meds
par(mar = c(5, 4, .5, .5))
matplot(c(Ns, Ns_xtra) * 3L, meds, lty = 1:3, type = "l", log = "xy", 
        ylab = "seconds", xlab = "N", col = "black")
```

# References
